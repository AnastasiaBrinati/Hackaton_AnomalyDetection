# ğŸ¯ Sistema di Valutazione Automatica SIAE Hackathon

## Panoramica

Questo sistema fornisce una valutazione automatica e una leaderboard in tempo reale per l'hackathon SIAE di anomaly detection. I partecipanti submittano file JSON standardizzati che vengono automaticamente valutati e classificati.

## ğŸ“ Struttura File

```
â”œâ”€â”€ submissions/                     # Cartella per i file di submission
â”‚   â”œâ”€â”€ submission_example.json      # Esempio formato submission
â”‚   â””â”€â”€ submission_[TEAM_NAME].json  # File submission dei team
â”œâ”€â”€ evaluate_submissions.py          # Script valutazione automatica
â”œâ”€â”€ update_leaderboard.py           # Script aggiornamento leaderboard
â”œâ”€â”€ leaderboard.md                   # Leaderboard live
â””â”€â”€ Track1_Solution/                 # Soluzione di esempio
    â””â”€â”€ track1_anomaly_detection.py  # Include generate_submission()
```

## ğŸš€ Setup per Organizzatori

### 1. Preparazione Iniziale

```bash
# Assicurati che tutti i file siano presenti
ls submissions/ evaluate_submissions.py update_leaderboard.py

# Testa il sistema di valutazione
python evaluate_submissions.py

# Verifica la leaderboard
cat leaderboard.md
```

### 2. Setup Sistema Automatico

**PRIMA dell'hackathon - Setup iniziale:**
```bash
# Setup completo del sistema automatico
python setup_auto_leaderboard.py
```

### 3. Durante l'Hackathon

#### ModalitÃ  Automatica (Raccomandata)
```bash
# Opzione 1: Git Hook (automatico sui commit)
# Nessuna azione richiesta - si attiva automaticamente!

# Opzione 2: File Watcher (tempo reale)
python file_watcher.py
```

#### ModalitÃ  Manuale
```bash
# Aggiornamento rapido manuale
./update_leaderboard_manual.sh

# Oppure diretto
python evaluate_submissions.py
```

### 4. Verifica Sistema

```bash
# 1. Setup sistema automatico
python setup_auto_leaderboard.py

# 2. Test manuale
./update_leaderboard_manual.sh

# 3. Genera submission di esempio
cd Track1_Solution
python track1_anomaly_detection.py

# 4. Verifica che il file sia stato creato
ls ../submissions/submission_me_giorgio.json

# 5. Test aggiornamento automatico
cd ..
git add submissions/submission_me_giorgio.json
git commit -m "Test submission"
# La leaderboard dovrebbe aggiornarsi automaticamente!
```

## ğŸ‘¥ Istruzioni per i Partecipanti

### Per i Team

1. **Sviluppa** il modello di anomaly detection
2. **Modifica** `team_name` e `members` in `generate_submission()`
3. **Esegui** lo script per generare il file JSON
4. **Committa e pusha** il file nella cartella `submissions/`

### Esempio per i Partecipanti

```python
# Nel file track1_anomaly_detection.py
team_name = "Gli Algoritmi Vincenti"
members = ["Mario Rossi", "Laura Bianchi", "Giuseppe Verdi"]

submission_file, submission_data = generate_submission(
    df=df, 
    iso_forest=iso_forest, 
    feature_cols=feature_cols,
    team_name=team_name,
    members=members
)
```

```bash
# Comandi git per submission
git add submissions/submission_gli_algoritmi_vincenti.json
git commit -m "Gli Algoritmi Vincenti - Track 1 submission"
git push origin main
```

## ğŸ“Š Sistema di Scoring

### Componenti del Score (0-1 scale)

#### Technical Score (50%)
- **F1-Score** (25%): Performance principale
- **AUC-ROC** (15%): Robustezza del modello  
- **Precision** (10%): Accuratezza anomalie

#### Innovation Score (30%)
- **Feature Diversity** (10%): Numero e varietÃ  features
- **Algorithm Complexity** (10%): ComplessitÃ  tecnica
- **Feature Engineering** (10%): Features create

#### Business Score (20%)
- **Performance Efficiency** (10%): Tempo e memoria
- **Interpretability** (10%): Breakdown anomalie

### Formula Final Score
```
Final Score = (Technical Ã— 0.5) + (Innovation Ã— 0.3) + (Business Ã— 0.2)
```

## ğŸ”§ Configurazione Avanzata

### Personalizzazione Scoring

Modifica i pesi in `evaluate_submissions.py`:

```python
# In calculate_innovation_score()
feature_score = min(len(features) * 2, 40)  # Modifica punteggio per feature

# In calculate_business_score()
if train_time < 10:
    score += 20  # Modifica bonus per velocitÃ 
```

### Validazione Custom

Aggiungi validazioni in `validate_submission()`:

```python
# Esempio: verifica numero minimo features
if len(submission_data['model_info']['features_used']) < 5:
    errors.append("Minimum 5 features required")
```

## ğŸ“ˆ Monitoring e Logging

### Log delle Valutazioni

Il sistema stampa:
- âœ… Submission valide processate
- âŒ Errori di validazione  
- ğŸ† Top 3 team
- ğŸ“Š Statistiche generali

### Notifiche

Estendi `send_notification()` per:
- Slack/Discord webhooks
- Email notifications
- Dashboard aggiornamenti

```python
def send_notification(team_name, score, rank):
    # Slack example
    import requests
    webhook_url = "YOUR_SLACK_WEBHOOK"
    message = f"ğŸ† New submission! {team_name} - Rank #{rank}"
    requests.post(webhook_url, json={"text": message})
```

## ğŸ”§ Metodi di Aggiornamento Automatico

### 1. Git Hook (Consigliato per produzione)
- âœ… **Si attiva automaticamente** sui commit con submissions
- âœ… **Zero manutenzione** durante l'hackathon
- âœ… **Commita automaticamente** le leaderboard aggiornate
- ğŸ”§ Setup: `python setup_auto_leaderboard.py`

### 2. File Watcher (Consigliato per testing)
- âœ… **Tempo reale** - aggiorna immediatamente sui file changes
- âœ… **Monitoring continuo** della cartella submissions
- âš ï¸ Richiede **processo attivo**: `python file_watcher.py`

### 3. Manuale (Backup)
- âœ… **Controllo completo** sugli aggiornamenti
- âœ… **Debugging facile** per problemi
- ğŸ”§ Uso: `./update_leaderboard_manual.sh`

## ğŸ› ï¸ Troubleshooting

### Problemi di Aggiornamento Automatico

#### "Git hook non si attiva"
```bash
# Verifica esistenza hook
ls -la .git/hooks/post-commit

# Verifica permessi esecuzione
chmod +x .git/hooks/post-commit

# Re-setup se necessario
python setup_auto_leaderboard.py
```

#### "File watcher non funziona"
```bash
# Installa dipendenza mancante
pip install watchdog

# Verifica cartella submissions
ls -la submissions/

# Avvia con debug
python file_watcher.py
```

#### "Environment non trovato"
```bash
# Verifica esistenza environment
ls -la hackathon_env/

# Attiva manualmente se necessario
source hackathon_env/bin/activate
python evaluate_submissions.py
```

### Problemi Comuni

#### "No submission files found"
```bash
# Verifica cartella submissions
ls -la submissions/
# Dovrebbe contenere file submission_*.json
```

#### "Ground truth file not found"
```bash
# Verifica esistenza file di riferimento
ls Track1_Solution/live_events_with_anomalies.csv
# Se mancante, esegui prima la soluzione di esempio
```

#### "JSON format errors"
```bash
# Valida JSON file
python -m json.tool submissions/submission_team.json
# Dovrebbe restituire JSON formattato senza errori
```

### Reset Sistema

```bash
# Pulisci submissions per test
rm submissions/submission_*.json
# Mantieni solo submission_example.json

# Rigenera leaderboard vuota
python evaluate_submissions.py
```

## ğŸ“‹ Checklist Pre-Hackathon

- [ ] âœ… **Setup automatico eseguito**: `python setup_auto_leaderboard.py`
- [ ] âœ… **Git hook testato**: commit di prova con submission
- [ ] âœ… **Environment hackathon_env** configurato e funzionante
- [ ] âœ… Sistema di valutazione testato
- [ ] âœ… Leaderboard iniziale configurata  
- [ ] âœ… File di esempio funzionante
- [ ] âœ… Istruzioni per partecipanti chiare
- [ ] âœ… Backup file importanti
- [ ] âœ… Permessi Git repository configurati
- [ ] âœ… **Watchdog installato** per file monitoring
- [ ] âœ… **Script manuali testati**: `./update_leaderboard_manual.sh`

## ğŸ“‹ Checklist Durante Hackathon

### Ogni Ora
- [ ] Verifica leaderboard aggiornata
- [ ] Controlla log errori
- [ ] Monitora performance sistema

### Ad Ogni Submission
- [ ] Valida formato JSON
- [ ] Verifica metriche ragionevoli
- [ ] Controlla posizione leaderboard

### Fine Giornata
- [ ] Backup submissions
- [ ] Report statistiche giornaliere
- [ ] Verifica integritÃ  dati

## ğŸ¯ Best Practices

1. **Comunicazione**: Informa i team su formato richiesto
2. **Monitoring**: Tieni attivo il monitoraggio automatico
3. **Backup**: Salva submissions regolarmente
4. **Trasparenza**: Leaderboard sempre visibile
5. **Support**: Help desk per problemi tecnici

## ğŸ“ Support

Per problemi tecnici durante l'hackathon:
1. Verifica log degli errori
2. Controlla formato JSON submission
3. Testa manualmente valutazione
4. Contatta team tecnico se necessario 