% !TEX root = main.tex
\documentclass[a4paper, 11pt]{article}

% Pacchetti per la lingua e la codifica
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}

% Pacchetti per la formattazione
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Implementazione di un sistema RAG agentico robusto}
\fancyfoot[C]{\thepage}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\usepackage{graphicx}
\usepackage{array}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumitem}

% Informazioni sul documento
\title{Implementazione di un sistema RAG agentico robusto per documenti eterogenei}
\author{Mirko Calcaterra}
\date{\today}

\begin{document}
\maketitle
\thispagestyle{empty}
\clearpage

\begin{abstract}
\noindent Il presente rapporto delinea un approccio multifase e di livello esperto per lo sviluppo di un sistema di Generazione Aumentata tramite Recupero (RAG) agentico. Questo sistema è progettato per elaborare documenti PDF altamente diversi, in particolare ricette ed elenchi di ingredienti, senza fare affidamento sul layout visivo e gestendo efficacemente il vocabolario ripetitivo specifico del dominio. Viene proposta un'architettura completa che comprende l'estrazione avanzata del testo, il chunking intelligente, l'integrazione di knowledge graph per la disambiguazione, il recupero ibrido con reranking e un sofisticato livello di orchestrazione agentica. Questa strategia garantisce un'estrazione delle informazioni ad alta fedeltà, una comprensione contestuale precisa e risposte dinamiche e intelligenti, elementi cruciali per la gestione di query culinarie complesse.
\end{abstract}

\tableofcontents
\clearpage

\section{Introduzione: navigare le complessità del RAG agentico per documenti di ricette diversi}

La proliferazione di documenti digitali, specialmente in formati non strutturati come i PDF, presenta sfide significative per l'estrazione e l'utilizzo automatizzato delle informazioni. Quando si costruiscono sistemi di intelligenza artificiale avanzati come la Generazione Aumentata tramite Recupero (RAG) all'interno di un framework agentico, queste sfide sono aggravate, in particolare in domini specializzati come le arti culinarie. I documenti di ricette sono intrinsecamente diversi, spesso privi di layout coerenti, contenenti contenuti misti (testo, tabelle, immagini) e caratterizzati da un vocabolario altamente ripetitivo (ad esempio, nomi di ingredienti, verbi di preparazione). Questa sezione introduce le complessità uniche di questo dominio e fornisce una panoramica della soluzione multifase proposta.

\subsection{Comprendere le sfide uniche: PDF eterogenei, indipendenza dal layout e vocabolario di dominio ripetitivo}

L'implementazione di un sistema RAG agentico in questo contesto specifico è ostacolata da tre sfide principali, che richiedono soluzioni mirate e sofisticate.
\begin{itemize}
    \item \textbf{PDF eterogenei e indipendenza dal layout:} I documenti PDF di ricette possono provenire da una moltitudine di fonti, come libri di cucina scansionati, blog di ricette online, appunti scritti a mano convertiti in PDF o persino immagini di ricette. Questa eterogeneità si traduce in ampie variazioni nella qualità visiva, nei tipi di carattere, nelle dimensioni e nella struttura complessiva. \cite{ocr_best_practices} I PDF possono contenere livelli di testo nascosti o immagini incorporate, rendendo difficile l'estrazione accurata dei dati. \cite{algodocs_challenges} I documenti scansionati, in particolare, sono problematici a causa della scarsa qualità o dell'allineamento incoerente, delle ombre, delle rotazioni e della formattazione variabile. \cite{algodocs_challenges} La richiesta dell'utente di non poter fare affidamento sul layout ("senza poter fare affidamento sul layout") è una restrizione critica, poiché molti modelli tradizionali di comprensione dei documenti dipendono fortemente dagli indizi visivi per segmentare e interpretare il testo. \cite{amazon_science_heterogenous} Questo impone la necessità di un approccio robusto all'estrazione del testo che privilegi il contenuto rispetto alla struttura visiva.
    \item \textbf{Vocabolario di dominio ripetitivo:} I documenti di ricette utilizzano frequentemente le stesse parole per gli ingredienti (ad esempio, "sale", "zucchero", "farina") o i nomi delle ricette in contesti diversi (query dell'utente). Questa elevata sovrapposizione lessicale può portare ad ambiguità e a una riduzione della precisione nella ricerca semantica e nel Riconoscimento di Entità Nominate (NER). La difficoltà risiede nel distinguere tra entità o concetti distinti quando i termini sono così comuni. Ad esempio, "mela" potrebbe riferirsi al frutto, al nome di una ricetta ("torta di mele") o a un'altra entità che non ha nulla a che fare con il cibo. Questa ambiguità lessicale è una sfida significativa per i sistemi che si basano sulla somiglianza semantica per il recupero delle informazioni. \cite{nlp_challenges}
\end{itemize}

\subsection{Panoramica dell'approccio multifase proposto}

Per affrontare queste complessità, viene proposta una pipeline strutturata e multifase:
\begin{enumerate}
   \item \textbf{Ingestione robusta dei documenti ed estrazione del testo indipendente dal layout:} concentrarsi sull'estrazione del testo ad alta fedeltà, dando priorità al contenuto rispetto alla struttura visiva, utilizzando OCR avanzato e metodi indipendenti dal layout.
   \item \textbf{Comprensione semantica - chunking intelligente e riconoscimento di entità nominate:} impiegare strategie di chunking adattive e NER specializzato per segmentare e strutturare le informazioni delle ricette, mitigando i problemi derivanti dal vocabolario ripetitivo.
   \item \textbf{Arricchimento della conoscenza - sfruttare i knowledge graph:} costruire un knowledge graph specifico del dominio per disambiguare le entità, normalizzare i sinonimi e catturare relazioni complesse all'interno dei dati delle ricette.
   \item \textbf{Recupero migliorato - ricerca ibrida e reranking:} combinare la ricerca per parole chiave e la ricerca semantica con il reranking per garantire un recupero delle informazioni completo e preciso.
   \item \textbf{Orchestrazione agentica - progettazione del sistema RAG intelligente:} implementare un livello di agente intelligente capace di ragionamento dinamico, pianificazione e utilizzo di strumenti per gestire query culinarie complesse.
\end{enumerate}

\section{Fase 1: fondazione - ingestione robusta dei documenti ed estrazione del testo indipendente dal layout}

Il primo passo critico è estrarre accuratamente il testo da diversi documenti PDF senza fare affidamento sul loro layout visivo. Ciò richiede un approccio robusto al Riconoscimento Ottico dei Caratteri (OCR) e all'estrazione del testo che possa gestire la qualità e le strutture variabili dei documenti.

\subsection{OCR avanzato e preprocessing delle immagini per qualità PDF variabili}

Dato che i documenti di ricette possono provenire da varie fonti (ad esempio, libri di cucina scansionati, appunti scritti a mano, file digitali), la loro qualità può essere altamente variabile, spesso caratterizzata da scarsa risoluzione, allineamento incoerente o persino caratteri diversi. \cite{algodocs_challenges} Un OCR robusto è il passo fondamentale per convertire questi diversi input visivi in testo leggibile dalla macchina. Se l'estrazione iniziale del testo è di scarsa qualità, gli errori si propagheranno attraverso l'intera pipeline RAG, portando a chunk imprecisi, embedding difettosi, recupero inefficace e, in ultima analisi, risposte inaffidabili del modello linguistico di grandi dimensioni (LLM). Pertanto, un investimento significativo in un preprocessing OCR robusto non è solo una buona pratica, ma un passo critico e fondamentale che influisce direttamente sulla qualità di tutti i componenti RAG successivi. Garantisce che l'input testuale grezzo sia il più pulito e accurato possibile, indipendentemente dalla qualità fisica o dal formato del documento originale.
\begin{itemize}
   \item \textbf{Tecniche chiave di preprocessing:} per massimizzare la precisione dell'OCR, è essenziale una serie di passaggi di preprocessing. Questi includono:
   \begin{itemize}
        \item \textbf{Miglioramento della risoluzione:} scansionare o ridimensionare le immagini a 300-400 DPI per il testo standard e 400-600 DPI per il testo più piccolo (dimensione del carattere < 8). \cite{ocr_best_practices} Ciò garantisce dettagli sufficienti per il riconoscimento dei caratteri.
        \item \textbf{Correzione di inclinazione e rotazione (skew and rotation correction):} raddrizzare i documenti inclinati e correggere le rotazioni accidentali assicura che il testo sia allineato orizzontalmente, prevenendo errori di lettura. \cite{conexiom_ocr_problems}
        \item \textbf{Rimozione del rumore:} eliminare macchie, sbavature e altre imperfezioni che possono interferire con il riconoscimento dei caratteri. \cite{survey_ocr_preprocessing} Tecniche come il filtraggio bilaterale adattivo (image despeckling) sono efficaci in questo contesto. \cite{survey_ocr_preprocessing}
        \item \textbf{Binarizzazione e miglioramento del contrasto:} convertire le immagini a colori/scala di grigi in un netto bianco e nero per migliorare la visibilità e il contrasto del testo. \cite{survey_ocr_preprocessing} Questo semplifica il processo OCR facendo risaltare i caratteri.
        \item \textbf{Assottigliamento e scheletrizzazione (thinning and skeletonization):} soprattutto per il testo scritto a mano, questo riduce la larghezza dei caratteri a una singola linea di pixel, semplificando le forme senza perdere informazioni essenziali. \cite{docuclipper_ocr_preprocessing}
   \end{itemize}
    \item \textbf{Strumenti open-source:} librerie come OpenCV e Pillow in Python \cite{nextgeninvent_ocr_python} forniscono funzioni per la normalizzazione, la correzione dell'inclinazione, il ridimensionamento delle immagini, la rimozione del rumore, la conversione in scala di grigi e la sogliatura. Leptonica e ImageMagick sono anche librerie di elaborazione delle immagini di uso generale utili per il preprocessing OCR. \cite{survey_ocr_preprocessing}
\end{itemize}

\subsection{Tecniche per l'estrazione del testo indipendente dal layout}

Una volta che le immagini sono pre-elaborate, la sfida successiva è estrarre il testo in modo indipendente dal layout, il che è particolarmente cruciale per i documenti di ricette che potrebbero non seguire una struttura standardizzata. L'esplicita richiesta di non fare affidamento sul layout è una limitazione tecnica fondamentale. I modelli tradizionali di comprensione dei documenti spesso si basano sull'analisi del layout. \cite{survey_deep_learning_ocr} Tuttavia, per i documenti di ricette eterogenei, non si può presumere un layout coerente. La capacità di comprendere la struttura e le relazioni testuali senza una dipendenza rigida dal layout è quindi essenziale per garantire che il sistema possa "comprendere" il contenuto del documento, indipendentemente dalla sua presentazione visiva.
\begin{itemize}
    \item \textbf{Modelli linguistici di grandi dimensioni multimodali (LMM):} gli LMM come GPT-4o e GPT-4 Vision sono altamente efficaci in quanto possono elaborare direttamente documenti visualmente ricchi (LRD). \cite{amazon_science_heterogenous} Essi utilizzano congiuntamente le caratteristiche testuali e visive, consentendo loro di comprendere il contenuto in modo completo senza la necessità di informazioni esplicite sul layout. \cite{problem_solved_layout_extraction} Questa capacità li rende intrinsecamente indipendenti dal layout, poiché possono inferire relazioni e contenuti dall'aspetto visivo anche se gli indizi di layout tradizionali sono assenti o inaffidabili. Possono eguagliare o persino superare modelli specializzati e fine-tuned come LayoutLMv3. \cite{problem_solved_layout_extraction}
    \item \textbf{Librerie Python per l'estrazione del testo:}
    \begin{itemize}
        \item \textbf{PyMuPDF (fitz):} questa libreria è altamente efficace per estrarre testo da PDF non strutturati, concentrandosi sui bounding box. \cite{analytics_vidhya_pdf_extraction} Può estrarre tutte le parole insieme alle loro coordinate, consentendo il filtraggio e l'ordinamento del testo all'interno di specifiche regioni di interesse, indipendentemente dal layout generale del documento. \cite{analytics_vidhya_pdf_extraction} Ciò è particolarmente prezioso per isolare ingredienti o istruzioni che potrebbero essere raggruppati visivamente ma non seguire un flusso lineare rigoroso.
        \item \textbf{Kreuzberg:} una libreria Python leggera che esegue l'estrazione del testo localmente senza chiamate API. \cite{medium_kreuzberg} Utilizza pdfium2 per i PDF ricercabili e Tesseract OCR per il contenuto scansionato. Sebbene possa appiattire le strutture delle tabelle \cite{medium_kreuzberg}, per un approccio indipendente dal layout incentrato sul contenuto testuale, questo potrebbe essere accettabile. La sua elaborazione locale è vantaggiosa per i costi e la privacy dei dati.
    \end{itemize}
    \item \textbf{Embedding posizionali 2D:} queste tecniche aumentano i metodi di Riconoscimento di Entità Nominate (NER) incorporando gli attributi dei bounding box 2D (coordinate x, y) e fondendoli con gli embedding del testo. \cite{problem_solved_layout_extraction} Ciò consente ai modelli di comprendere le relazioni spaziali tra le unità di testo senza fare affidamento su un layout rigido e predefinito. DOCPOLARBERT, ad esempio, utilizza coordinate polari relative, sostenendo che riducono il rumore introdotto dalle posizioni spaziali assolute. \cite{docpolarbert} Questo metodo aiuta a inferire l'ordine di lettura logico o a raggruppare elementi di testo correlati anche in documenti visivamente caotici.
    \item \textbf{Reti neurali grafiche (GNN):} le GNN rappresentano i documenti come grafi in cui i segmenti di testo (parole, righe, blocchi) sono nodi e gli archi definiscono le relazioni tra di essi. \cite{survey_deep_learning_ocr} Queste relazioni possono essere basate sulla prossimità spaziale (ad esempio, k-vicini più prossimi) o su altre connessioni inferite. DocGraphLM, ad esempio, combina le GNN con modelli linguistici pre-addestrati e utilizza una nuova euristica Direction Line-of-sight (D-LoS) per costruire gli archi, affrontando le limitazioni dei metodi di prossimità più semplici. \cite{docgraphlm_v1} Questo approccio è intrinsecamente indipendente dal layout perché si concentra sulla struttura relazionale delle informazioni piuttosto che su una griglia visiva rigida, rendendolo robusto a layout di documenti diversi e irregolari.
\end{itemize}

\begin{longtable}{>{\raggedright\arraybackslash}p{2.5cm} >{\raggedright\arraybackslash}p{2.2cm} >{\raggedright\arraybackslash}p{2.2cm} >{\raggedright\arraybackslash}p{2.2cm} >{\raggedright\arraybackslash}p{2.2cm} >{\raggedright\arraybackslash}p{2.2cm}}
\caption{Confronto dei metodi di estrazione del testo indipendenti dal layout per i PDF}\\
\toprule
\textbf{Caratteristica/Metodo} & \textbf{LLM multimodali (es. GPT-4 Vision)} & \textbf{PyMuPDF (fitz)} & \textbf{Kreuzberg} & \textbf{Embedding posizionali 2D} & \textbf{Reti neurali grafiche (GNN)} \\
\midrule
\endfirsthead
\multicolumn{6}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\toprule
\textbf{Caratteristica/Metodo} & \textbf{LLM multimodali (es. GPT-4 Vision)} & \textbf{PyMuPDF (fitz)} & \textbf{Kreuzberg} & \textbf{Embedding posizionali 2D} & \textbf{Reti neurali grafiche (GNN)} \\
\midrule
\endhead
\bottomrule
\endfoot
Dipendenza dal layout & Bassa (elaborazione congiunta visiva/testuale) \cite{problem_solved_layout_extraction} & Bassa (focalizzato sui bounding box) \cite{analytics_vidhya_pdf_extraction} & Bassa (incentrato sul testo) \cite{medium_kreuzberg} & Bassa (codifica spaziale relativa) \cite{docpolarbert} & Bassa (struttura relazionale) \cite{gnn_benchmarking} \\
\addlinespace
PDF scansionati & Eccellente (OCR multimodale) \cite{problem_solved_layout_extraction} & Buono (integrazione Tesseract OCR) \cite{analytics_vidhya_pdf_extraction} & Buono (integrazione Tesseract OCR) \cite{medium_kreuzberg} & Buono (se l'output OCR è accurato) & Buono (se l'output OCR è accurato) \\
\addlinespace
PDF ricercabili & Eccellente (elaborazione diretta) \cite{problem_solved_layout_extraction} & Eccellente (estrazione nativa del testo) \cite{analytics_vidhya_pdf_extraction} & Eccellente (pdfium2) \cite{medium_kreuzberg} & Eccellente & Eccellente \\
\addlinespace
Dati strutturati (tabelle) & Buono (può interpretare tabelle visive) \cite{problem_solved_layout_extraction} & Discreto (può estrarre tabelle tramite Camelot) \cite{analytics_vidhya_pdf_extraction} & Scarso (appiattisce le tabelle) \cite{medium_kreuzberg} & Limitato (richiede parsing aggiuntivo) & Buono (può modellare la struttura delle tabelle) \cite{survey_deep_learning_ocr} \\
\addlinespace
Costo/complessità & Alto (costi API, dimensione del modello) \cite{problem_solved_layout_extraction} & Basso (libreria locale) \cite{analytics_vidhya_pdf_extraction} & Basso (libreria locale) \cite{medium_kreuzberg} & Medio (richiede implementazione personalizzata) & Alto (architettura complessa) \cite{survey_deep_learning_ocr} \\
\addlinespace
Supporto alla disambiguazione & Alto (comprensione semantica) & Basso (output di testo grezzo) & Basso (output di testo grezzo) & Medio (contesto spaziale) & Alto (contesto relazionale) \\
\addlinespace
Note & State-of-the-art, minore perdita di contesto. \cite{problem_solved_layout_extraction} & Estrazione precisa dei bounding box. \cite{analytics_vidhya_pdf_extraction} & Leggero, senza API. \cite{medium_kreuzberg} & Aumenta gli embedding del testo. \cite{problem_solved_layout_extraction} & Modella le relazioni tra gli elementi del testo. \cite{gnn_benchmarking} \\
\end{longtable}

\section{Fase 2: comprensione semantica - chunking intelligente e riconoscimento di entità nominate}
Una volta che il testo è stato estratto in modo affidabile, la sfida successiva è trasformare questo testo grezzo in unità significative che possano essere efficacemente utilizzate da un sistema RAG. Questo è particolarmente complesso per i documenti di ricette a causa del vocabolario ripetitivo.

\subsection{Strategie di chunking adattive per il vocabolario ripetitivo delle ricette}
Un chunking efficace è cruciale per i sistemi RAG, poiché influisce direttamente sulla pertinenza e sulla coerenza delle informazioni recuperate. \cite{semantic_chunking_multimodal} Per i documenti di ricette, la sfida è amplificata dalla frequente ripetizione dei nomi degli ingredienti e dei termini culinari comuni (query dell'utente), che può portare a risultati di ricerca imprecisi o alla perdita di contesto se i chunk sono troppo piccoli o mal divisi. \cite{chunking_strategies_pinecone} Se una strategia di chunking non tiene conto del vocabolario ripetitivo, molti chunk conterranno termini comuni come "sale", "zucchero" o "acqua", portando a una scarsa distinzione semantica e a un recupero irrilevante. \cite{semantic_chunking_ani}
\begin{itemize}
    \item \textbf{Chunking a dimensione fissa (fixed-size chunking):} sebbene semplice da implementare \cite{f22_chunking_strategies}, questo metodo divide il testo in chunk uniformi basati sul conteggio di caratteri o token. \cite{chunking_strategies_ibm} Spesso interrompe frasi o paragrafi a metà \cite{semantic_chunking_ani}, portando alla frammentazione del contesto ed è generalmente subottimale per i sistemi RAG di produzione, specialmente con contenuti diversi. \cite{databricks_unstructured_data} L'overlap (10-20\%) può mitigare una parte della perdita di contesto. \cite{semantic_chunking_multimodal}
    \item \textbf{Divisione ricorsiva dei caratteri (recursive character text splitting):} questo approccio adattivo utilizza più separatori (ad esempio, \textbackslash n\textbackslash n, \textbackslash n, ., ) in un ordine specificato per trovare confini significativi. \cite{chunking_strategies_ibm} Tenta di mantenere paragrafi, frasi e parole il più possibile insieme, preservando il flusso logico. \cite{chunking_strategies_ibm} Offre maggiore flessibilità rispetto al chunking a dimensione fissa, ma potrebbe comunque richiedere una messa a punto. \cite{semantic_chunking_ani}
    \item \textbf{Chunking semantico (semantic chunking):} questo metodo avanzato divide il testo in base alla somiglianza semantica dei loro embedding, garantendo che ogni chunk rappresenti un concetto o un'idea coerente. \cite{semantic_chunking_multimodal} Implica il rilevamento dei confini delle frasi, la modellazione degli argomenti o la segmentazione basata sugli embedding. \cite{semantic_chunking_ani} Questo è particolarmente vantaggioso per i documenti di ricette in quanto raggruppa idee correlate, garantendo che un chunk su "aggiungere sale a piacere" sia semanticamente distinto da "contenuto di sale per porzione", anche se entrambi contengono la parola "sale". \cite{semantic_chunking_multimodal} Il chunking semantico assicura che i chunk rappresentino idee complete o cambiamenti tematici piuttosto che segmenti di testo arbitrari.
    \item \textbf{Chunking consapevole dei metadati (metadata-aware chunking):} questa strategia arricchisce i chunk con informazioni strutturate aggiuntive (metadati) estratte dal documento, come intestazioni, titoli di sezione, numeri di pagina e nomi di documenti. \cite{semantic_chunking_multimodal} Per le ricette, questo potrebbe includere nomi di ricette, tipi di cucina, tempi di preparazione o restrizioni dietetiche. L'associazione di questi metadati consente un filtraggio e un recupero altamente precisi, consentendo al sistema RAG di restringere efficacemente i risultati di ricerca anche con vocabolario ripetitivo. \cite{metadata_aware_chunking_asimsultan} Strumenti come PyMuPDF o Unstructured.io possono aiutare nel parsing strutturato per l'estrazione dei metadati. \cite{metadata_aware_chunking_asimsultan} L'aggiunta di metadati come il nome della ricetta, il tipo di portata, il tempo di preparazione o le restrizioni dietetiche \cite{ai_recipe_generator} a ciascun chunk consente un filtraggio altamente preciso prima della ricerca semantica, migliorando significativamente la precisione nonostante i nomi degli ingredienti ripetitivi.
    \item \textbf{Chunking agentico (agentic chunking):} questo approccio sperimentale ma promettente sfrutta un LLM per determinare dinamicamente la divisione appropriata del documento in base al significato semantico e alla struttura del contenuto. \cite{chunking_strategies_ibm} Simula il ragionamento umano nell'identificazione dei punti di interruzione logici, rendendolo altamente adattivo per formati di ricette diversi e non strutturati che potrebbero non aderire a regole rigide. \cite{chunking_strategies_ibm} Questo approccio si allinea perfettamente con la natura agentica del sistema, consentendo all'agente LLM di decidere come suddividere il testo in base al significato semantico e alla struttura del contenuto, adattandosi dinamicamente ai diversi stili di ricetta.
    \item \textbf{Determinazione della dimensione ottimale del chunk:} la dimensione ideale del chunk è critica e spesso richiede sperimentazione. \cite{chunking_strategies_ibm} Chunk più piccoli possono consentire un recupero più granulare ma potrebbero mancare di un contesto più ampio, mentre chunk più grandi preservano più contesto ma possono diluire corrispondenze specifiche. \cite{enhancing_rag_ibm} L'obiettivo è trovare una dimensione in cui venga mantenuto un significato chiaro e singolo. \cite{semantic_chunking_multimodal} Un overlap (10-20\%) tra i chunk è generalmente raccomandato per preservare la continuità contestuale. \cite{semantic_chunking_multimodal}
\end{itemize}

\subsection{Riconoscimento di Entità Nominate (NER) per Ingredienti, Quantità e Componenti delle Ricette}
Per utilizzare efficacemente il testo non strutturato delle ricette, è necessario trasformarlo in un formato strutturato e leggibile dalla macchina. Il Riconoscimento di Entità Nominate (NER) è una tecnica chiave per questo, identificando e classificando parole chiave e frasi specifiche in categorie predeterminate. \cite{deep_learning_ner_recipes} La trasformazione del testo non strutturato in entità strutturate è fondamentale per il funzionamento del sistema. Senza questa capacità, il sistema non sarebbe in grado di distinguere in modo affidabile tra "mela" come frutto e "mela" come azienda, o di comprendere che "2 tazze" si riferisce a una quantità. Questo output strutturato è il prerequisito per la costruzione di un robusto knowledge graph e per consentire all'agente di eseguire un ragionamento preciso e basato sui fatti sui dati delle ricette, passando dal semplice abbinamento di parole chiave a una vera comprensione semantica delle istruzioni culinarie.
\begin{itemize}
    \item \textbf{NER Specifico del Dominio:} Per le ricette, il NER viene utilizzato per estrarre entità come nomi di ingredienti, quantità, unità, prodotti, stati (ad esempio, "tritato", "fuso"), passaggi di lavorazione, protocolli di cottura e utensili. \cite{deep_learning_ner_recipes} Dato il vocabolario altamente specializzato, un modello NER generico potrebbe non essere sufficiente.
    \item \textbf{Metodi Basati su Reti Ricorrenti in Ensemble (RNE):} I modelli RNE hanno mostrato alte prestazioni (punteggio F1 del 96,09\%) nell'estrazione di entità di ingredienti alimentari, superando i singoli modelli. \cite{enhancing_food_ner_rne} Questi approcci ensemble sfruttano le reti neurali ricorrenti (RNN, GRU, LSTM) per catturare le informazioni sequenziali all'interno delle istruzioni delle ricette.
    \item \textbf{Modelli di Deep Learning:} Gli approcci NER moderni utilizzano anche modelli di deep learning come BERT, DistilBERT e spaCy. \cite{deep_learning_ner_recipes} La messa a punto di questi modelli su un dataset accuratamente annotato di entità di ingredienti alimentari (come il dataset FINER menzionato in \cite{enhancing_food_ner_rne}) è cruciale per raggiungere un'elevata precisione in questo dominio.
    \item \textbf{Output:} L'output del NER è costituito da dati strutturati (ad esempio, \{\texttt{"ingrediente": "farina", "quantità": "2 tazze", "unità": "tazze", "stato": "setacciata"}\}), che è essenziale per la costruzione di un knowledge graph e per consentire query precise.
\end{itemize}

\begin{longtable}{>{\raggedright\arraybackslash}p{2.5cm} >{\raggedright\arraybackslash}p{3.5cm} >{\raggedright\arraybackslash}p{3.5cm} >{\raggedright\arraybackslash}p{3cm} >{\raggedright\arraybackslash}p{3.5cm}}
\caption{Strategie di Chunking Avanzate per Documenti di Ricette}\\
\toprule
\textbf{Strategia} & \textbf{Descrizione} & \textbf{Vantaggi per le Ricette} & \textbf{Svantaggi per le Ricette} & \textbf{Miglior Caso d'Uso per le Ricette} \\
\midrule
\endfirsthead
\multicolumn{5}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\toprule
\textbf{Strategia} & \textbf{Descrizione} & \textbf{Vantaggi per le Ricette} & \textbf{Svantaggi per le Ricette} & \textbf{Miglior Caso d'Uso per le Ricette} \\
\midrule
\endhead
\bottomrule
\endfoot
A Dimensione Fissa \cite{chunking_strategies_ibm} & Divide il testo in chunk di lunghezza uniforme (caratteri/token). & Semplice da implementare, efficiente per grandi dataset. \cite{f22_chunking_strategies} & Può tagliare frasi/paragrafi, frammentando il contesto. \cite{semantic_chunking_ani} & Documenti con struttura molto uniforme, come elenchi di ingredienti semplici. \\
\addlinespace
Ricorsiva \cite{chunking_strategies_ibm} & Utilizza più separatori gerarchici (paragrafi, frasi) per trovare confini significativi. & Preserva l'integrità semantica e strutturale, flessibile a vari contenuti. \cite{f22_chunking_strategies} & Maggiore complessità, overhead computazionale. \cite{f22_chunking_strategies} & Ricette con istruzioni dettagliate e strutturate in paragrafi. \\
\addlinespace
Semantica \cite{semantic_chunking_multimodal} & Divide il testo in base alla somiglianza semantica degli embedding, mantenendo concetti coerenti. & Raggruppa idee correlate, migliora la precisione di recupero per vocabolario ripetitivo. \cite{semantic_chunking_multimodal} & Più lenta e complessa, richiede modelli di embedding. \cite{semantic_chunking_ani} & Ricette con descrizioni complesse, note culinarie, variazioni di ingredienti. \\
\addlinespace
Consapevole dei Metadati \cite{semantic_chunking_multimodal} & Arricchisce i chunk con metadati estratti (titoli, sezioni, autori, date). & Migliora la precisione di ricerca tramite filtraggio, fornisce contesto aggiuntivo. \cite{metadata_aware_chunking_asimsultan} & Richiede parsing strutturato e gestione dei metadati. \cite{metadata_aware_chunking_asimsultan} & Gestione di grandi collezioni di ricette con attributi specifici (es. cucina, dieta, autore). \\
\addlinespace
Agentica \cite{chunking_strategies_ibm} & Un LLM determina dinamicamente la suddivisione in base al significato semantico e alla struttura del contenuto. & Altamente adattiva a formati non strutturati e diversi, simula il ragionamento umano. \cite{chunking_strategies_ibm} & Sperimentale, può essere complessa da configurare, potenziale perdita di contesto globale. \cite{f22_chunking_strategies} & Ricette con layout molto irregolari o stili narrativi unici, che richiedono un'interpretazione dinamica. \\
\end{longtable}

\section{Fase 3: arricchimento della conoscenza - sfruttare i knowledge graph per la disambiguazione e le relazioni}
La presenza di "parole che si ripetono frequentemente negli ingredienti e nei nomi delle ricette" (query dell'utente) introduce una significativa ambiguità. Se un utente cerca "sale", una semplice ricerca basata sulla somiglianza testuale o semantica potrebbe recuperare molte ricette che menzionano il sale, ma non necessariamente nel contesto desiderato (ad esempio, "sale" come ingrediente principale vs. "sale" come parte di un'analisi nutrizionale). Questo rende la disambiguazione e la normalizzazione dei termini cruciali.

\subsection{Costruzione di un knowledge graph specifico del dominio per le ricette}
Un knowledge graph (KG) è una struttura dati che collega entità tra loro attraverso relazioni. \cite{understanding_kg} Le entità (nodi) sono oggetti con proprietà (metadati), e le relazioni (archi) descrivono le connessioni tra le entità. \cite{understanding_kg} Per il dominio delle ricette, un KG non è un semplice miglioramento, ma una necessità. Esso fornisce una rappresentazione strutturata e non ambigua di ingredienti, delle loro proprietà (ad esempio, "contenuto nutrizionale", "allergeni") e delle relazioni (ad esempio, "può sostituire", "è parte di"), cosa impossibile da ottenere con i soli embedding di testo grezzo, specialmente con vocabolario ripetitivo e ambiguo. Un KG alimentare (FoodKG) può modellare "mela" come una specifica entità frutto con proprietà (ad esempio, "è\_frutto", "contiene\_zucchero") e relazioni (ad esempio, "è\_ingrediente\_in: torta di mele"), distinguendola da altri usi di "mela". Questa rappresentazione strutturata \cite{understanding_kg} è fondamentale per un recupero accurato e per il ragionamento in un sistema agentico.
\begin{itemize}
    \item \textbf{Obiettivi del KG nel dominio culinario:}
    \begin{itemize}
        \item \textbf{Unificazione e organizzazione:} i KG come FoodKG mirano a unificare e organizzare le informazioni alimentari, collegando diversi silos relativi al cibo e alle ricette. \cite{foodkg}
        \item \textbf{Raccomandazioni e vincoli:} un KG può essere modellato per aiutare gli utenti a determinare quale ricetta preparare in base agli ingredienti disponibili e a vincoli come le allergie. \cite{foodkg}
        \item \textbf{Informazioni nutrizionali:} un KG può integrare informazioni nutrizionali con le preferenze dell'utente, collegando ricette con profili nutrizionali simili e fornendo raccomandazioni alimentari personalizzate. \cite{nutrition_kg_recommendation}
    \end{itemize}
    \item \textbf{Strumenti e framework open-source:} esistono framework e toolkit per la costruzione di KG alimentari. \cite{foodkg} Blazegraph è raccomandato per l'archiviazione del KG integrato. \cite{foodkg}
\end{itemize}

\subsection{Entity linking e disambiguazione per ingredienti e ricette}
Il processo di Entity Linking (EL), noto anche come disambiguazione di entità nominate (NED), è il compito di assegnare un'identità unica alle entità menzionate nel testo. \cite{entity_linking_wiki} Data la ripetizione dei nomi degli ingredienti (ad esempio, "zucchero", "farina") in molte ricette, la semplice corrispondenza testuale o la somiglianza semantica potrebbero recuperare molti chunk irrilevanti. L'EL risolve questo problema mappando le menzioni di testo grezzo a entità uniche nel knowledge graph (ad esempio, "zucchero" -> FoodIngredient:Zucchero). Questo processo include la disambiguazione \cite{entity_linking_wiki} per garantire che l'entità corretta sia identificata, anche se la parola è ambigua.
\begin{itemize}
    \item \textbf{Processo di entity linking:} l'EL si compone di tre fasi principali:
    \begin{enumerate}
        \item \textbf{Riconoscimento di entità nominate (NER):} estrazione delle entità nominate dal testo. \cite{entity_linking_wiki}
        \item \textbf{Generazione di candidati:} per ogni entità nominata, selezionare possibili candidati da una knowledge base (ad esempio, Wikidata, DBpedia o un KG specifico del dominio). \cite{entity_linking_wiki}
        \item \textbf{Disambiguazione:} scegliere l'entità corretta da questo insieme di candidati. \cite{entity_linking_wiki} I KG sono fondamentali in questa fase, poiché codificano informazioni semantiche ricche (attributi, tipi, relazioni) che aiutano a distinguere tra entità con nomi simili o identici. \cite{understanding_kg}
    \end{enumerate}
    \item \textbf{Tecniche avanzate di disambiguazione:}
    \begin{itemize}
        \item \textbf{Algoritmi di clustering di comunità grafiche:} possono essere utilizzati per raggruppare entità strettamente correlate, riducendo l'ambiguità. \cite{kg_entity_disambiguation} Per dati scarsamente popolati, algoritmi come il "Seed Algorithm" possono generare cluster meno ambigui. \cite{kg_entity_disambiguation}
        \item \textbf{Combinazione di embedding:} la combinazione di embedding del KG con embedding contestuali basati sul testo può migliorare la precisione della disambiguazione. \cite{ned_with_kg_harvard}
    \end{itemize}
\end{itemize}

\subsection{Integrazione del knowledge graph con il RAG (GraphRAG)}
L'integrazione di un KG nella pipeline RAG, nota come GraphRAG, offre una soluzione potente per il ragionamento complesso e multi-hop e per superare l'ambiguità intrinseca nei dati delle ricette. \cite{graphrag_explained} Permette al sistema agentico non solo di recuperare testo, ma di ragionare su fatti strutturati, portando a risposte più accurate e spiegabili. Per un sistema agentico che accede a PDF diversi, un RAG standard basato solo su chunk di testo potrebbe avere difficoltà con query complesse come "Quali sono gli allergeni comuni in questa ricetta e quali sono le sostituzioni adatte per essi?". \cite{ingredient_substitutions_kg} GraphRAG consente all'agente di ragionare sulle relazioni strutturate nel KG (ad esempio, "Ingrediente X è\_allergene\_per Allergia Y", "Ingrediente X può\_essere\_sostituito\_da Ingrediente Z"). Ciò fornisce capacità di ragionamento esplicite che vanno oltre la semplice somiglianza semantica, consentendo all'agente di gestire le query di ricette complesse in modo più efficace e accurato, riducendo le allucinazioni. \cite{kg_beyond_retrieval}
\begin{itemize}
    \item \textbf{Funzionamento di GraphRAG:}
    \begin{itemize}
        \item \textbf{Estrazione di entità, relazioni e affermazioni:} GraphRAG utilizza gli LLM per identificare ed estrarre tutte le entità, le relazioni tra di esse e le affermazioni chiave dal testo, costruendo un KG iniziale. \cite{graphrag_explained}
        \item \textbf{Tipi di ricerca:} può eseguire ricerche globali (per domande olistiche sull'intero corpus di dati) e ricerche locali (per entità specifiche, esplorando i loro vicini e concetti associati). \cite{graphrag_explained}
        \item \textbf{Riduzione dell'ambiguità e ragionamento esplicito:} i KG riducono l'ambiguità utilizzando identificatori di entità unici e ben definiti e consentono una disambiguazione esplicita del tipo e del contesto. \cite{what_is_entity_linking_ontotext}
        \item \textbf{Sistemi ibridi:} i sistemi avanzati possono combinare gli embedding vettoriali per generare candidati iniziali e i KG per un ragionamento preciso e spiegabile. \cite{kg_beyond_retrieval}
    \end{itemize}
\end{itemize}

\begin{longtable}{>{\raggedright\arraybackslash}p{4cm} >{\raggedright\arraybackslash}p{6cm} >{\raggedright\arraybackslash}p{6cm}}
\caption{Ruolo dei knowledge graph nell'estrazione di informazioni sulle ricette}\\
\toprule
\textbf{Funzione del KG} & \textbf{Descrizione} & \textbf{Vantaggi specifici per le ricette} \\
\midrule
\endfirsthead
\multicolumn{3}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\toprule
\textbf{Funzione del KG} & \textbf{Descrizione} & \textbf{Vantaggi specifici per le ricette} \\
\midrule
\endhead
\bottomrule
\endfoot
Disambiguazione delle entità \cite{entity_linking_wiki} & Assegna un'identità unica a termini ambigui (es. "mela" come frutto vs. "mela" come torta). & Distingue ingredienti simili o omonimi, garantendo precisione nel recupero. \\
\addlinespace
Normalizzazione dei sinonimi/variazioni \cite{ingredient_substitutions_kg} & Mappa termini diversi che si riferiscono alla stessa entità (es. "pomodoro" vs. "pomodorino"). & Coerenza nella rappresentazione degli ingredienti, recupero più completo. \\
\addlinespace
Cattura delle relazioni complesse \cite{understanding_kg} & Modella legami tra entità (es. "ingrediente\_di", "sostituibile\_con", "contiene\_allergene"). & Permette query complesse su sostituzioni, allergeni, profili nutrizionali. \\
\addlinespace
Arricchimento semantico \cite{understanding_kg} & Aggiunge proprietà strutturate (metadati) alle entità (es. nutrizione, tipo di cucina). & Fornisce contesto ricco per il ragionamento dell'agente e il filtraggio. \\
\addlinespace
Ragionamento esplicito (GraphRAG) \cite{graphrag_explained} & Consente al sistema di eseguire ragionamenti multi-hop sul grafo. & Risposte più accurate e spiegabili per query complesse (es. "ricette senza glutine per diabetici"). \\
\end{longtable}

\section{Fase 4: recupero migliorato - ricerca ibrida e reranking per precisione e recall}
Il recupero delle informazioni è una fase critica in un sistema RAG, e per i documenti di ricette con vocabolario ripetitivo, le strategie di ricerca tradizionali presentano limitazioni. La ricerca vettoriale, pur eccellendo nel trovare contenuti concettualmente correlati (alto recall), è meno efficace nel individuare esattamente ciò che serve (bassa precisione). \cite{meilisearch_vector_dbs} D'altra parte, la ricerca basata su parole chiave (come BM25) privilegia la precisione, ma può perdere contenuti semanticamente simili che utilizzano terminologie diverse. \cite{hybrid_search_vectorchord} Inoltre, l'inclusione di documenti recuperati irrilevanti nel contesto di output può portare a "allucinazioni" da parte dell'LLM. \cite{mastering_rag_reranking}

\subsection{Ricerca ibrida (BM25 + ricerca vettoriale)}
La ricerca ibrida colma il divario tra la ricerca basata su parole chiave e la ricerca semantica, combinando i punti di forza di entrambi gli approcci. \cite{hybrid_search_vectorchord} Per i documenti di ricette, la ricerca ibrida è essenziale. Se un utente cerca "sale", una ricerca vettoriale pura potrebbe restituire molte ricette che si limitano a menzionare il sale. BM25 \cite{hybrid_search_vectorchord} darebbe priorità ai documenti in cui "sale" è un termine chiave (ad esempio, "carni salate"). Al contrario, per una query come "dessert salutare", un BM25 puro potrebbe perdere ricette semanticamente simili che usano termini come "dolce nutriente". La ricerca ibrida garantisce sia corrispondenze precise per parole chiave comuni sia una comprensione semantica più ampia, cruciale per la natura diversa e ripetitiva dei documenti di ricette.
\begin{itemize}
    \item \textbf{BM25:} questo algoritmo di ranking probabilistico eccelle nel classificare i documenti in base alla frequenza dei termini e alle corrispondenze esatte delle parole chiave. \cite{hybrid_search_vectorchord} È particolarmente efficace per query strutturate e contenuti ricchi di parole chiave.
    \item \textbf{Ricerca vettoriale:} cattura il significato semantico profondo, consentendo una migliore generalizzazione tra query diverse. \cite{hybrid_search_vectorchord} Trasforma query e documenti in embedding vettoriali, trovando informazioni pertinenti anche quando le parole chiave esatte non corrispondono.
    \item \textbf{Combinazione degli approcci:} la ricerca ibrida fonde i risultati della ricerca vettoriale e della ricerca per parole chiave. Algoritmi di fusione come Reciprocal Rank Fusion (RRF) combinano e classificano i risultati in un'unica lista. \cite{hybrid_search_vectorchord} Questo approccio bilancia la specificità e la pertinenza, migliorando la precisione complessiva della ricerca.
\end{itemize}

\subsection{Meccanismi di reranking}
Il reranking è un passaggio di filtraggio e ordinamento secondario che riordina i documenti recuperati dal retriever iniziale. \cite{mastering_rag_reranking} Prioritizza gli elementi più pertinenti in base alla rilevanza query-documento, riducendo le allucinazioni filtrando i documenti non correlati. \cite{mastering_rag_reranking} Dopo la ricerca ibrida, viene restituito un elenco di chunk potenzialmente rilevanti. A causa della natura ripetitiva del vocabolario delle ricette, molti chunk potrebbero comunque essere recuperati che sono solo vagamente correlati. Il reranking agisce come un "secondo passaggio" di filtro, utilizzando un modello più potente (ad esempio, un cross-encoder o un modello basato su LLM come RankGPT) per rivalutare la rilevanza query-documento. Ciò garantisce che, se un utente chiede "ricette di pane senza glutine", il reranker dia priorità ai chunk che descrivono la preparazione del pane senza glutine rispetto a quelli che si limitano a menzionare il glutine o il pane, anche se i loro punteggi di somiglianza iniziali erano alti. Ciò migliora direttamente la qualità del contesto fornito all'LLM, riducendo la possibilità di risposte irrilevanti (allucinazioni). \cite{mastering_rag_reranking}
\begin{itemize}
    \item \textbf{Funzionamento:} il reranker prende un insieme iniziale di documenti recuperati e li riordina per garantire che i più rilevanti siano in cima alla lista. \cite{rankgpt_reranking} Questo aiuta a filtrare le informazioni meno utili e a concentrarsi su ciò che è importante.
    \item \textbf{Tipi di reranker:} esistono diversi tipi di modelli di reranking:
    \begin{itemize}
        \item \textbf{Cross-encoders:} offrono un'elevata precisione ma sono più lenti. \cite{mastering_rag_reranking}
        \item \textbf{Multi-vector models (es. ColBERT):} bilanciano prestazioni e costi. \cite{mastering_rag_reranking}
        \item \textbf{Modelli basati su LLM (es. RankGPT, RankZephyr):} possono essere promptati per migliorare autonomamente il reranking dei documenti. \cite{mastering_rag_reranking}
    \end{itemize}
    \item \textbf{Strategie:} possono utilizzare una strategia a finestra scorrevole (sliding window) per riordinare un sottoinsieme di documenti candidati alla volta, specialmente per documenti lunghi. \cite{mastering_rag_reranking}
\end{itemize}

\subsection{Tecniche di recupero contestuale}
Il recupero contestuale è una strategia proattiva per combattere il problema del "vocabolario ripetitivo" arricchendo i chunk con un contesto di livello superiore prima del recupero. \cite{contextual_retrieval_pluralsight} Il problema del vocabolario ripetitivo implica che i singoli chunk potrebbero non avere un contesto sufficiente per essere identificabili in modo univoco o semanticamente ricchi da soli. \cite{contextual_retrieval_mlexpert} Il recupero contestuale affronta questo problema arricchendo ogni chunk con metadati o riassunti generati dal suo contesto documentale più ampio (ad esempio, la ricetta completa, il suo titolo, il tipo di cucina). Quindi, un chunk su "farina" potrebbe essere aumentato con "Ricetta: Pancake Senza Glutine, Ingrediente: Farina di Mandorle". Ciò rende l'embedding del chunk più preciso e meno ambiguo, migliorando la precisione del recupero per query specifiche sulle ricette.
\begin{itemize}
    \item \textbf{Funzionamento:} migliora ogni chunk aggiungendo un contesto specifico ed esplicativo prima di incorporarlo o indicizzarlo. \cite{contextual_retrieval_pluralsight} Questo preserva la relazione tra il chunk e il suo documento più ampio, migliorando significativamente la capacità del sistema di recuperare e utilizzare le informazioni più pertinenti.
    \item \textbf{Metodi:} l'approccio di Contextual Retrieval di Anthropic \cite{contextual_retrieval_mlexpert} utilizza Contextual Embeddings e Contextual BM25, riducendo significativamente il tasso di fallimento del recupero. Questo può comportare l'invio dell'intero documento a un LLM per generare un contesto arricchito per ogni chunk. \cite{contextual_retrieval_somawansa}
\end{itemize}

% ***** TAVOLA CORRETTA QUI *****
\begin{longtable}{>{\raggedright\arraybackslash}p{3cm} >{\raggedright\arraybackslash}p{4.5cm} >{\raggedright\arraybackslash}p{4.5cm} >{\raggedright\arraybackslash}p{4.5cm}}
\caption{Tecniche di ottimizzazione del recupero nel RAG}\\
\toprule
\textbf{Tecnica} & \textbf{Descrizione} & \textbf{Vantaggi per le ricette} & \textbf{Svantaggi/considerazioni} \\
\midrule
\endfirsthead
\multicolumn{4}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\toprule
\textbf{Tecnica} & \textbf{Descrizione} & \textbf{Vantaggi per le ricette} & \textbf{Svantaggi/considerazioni} \\
\midrule
\endhead
\bottomrule
\endfoot
Ricerca ibrida \cite{hybrid_search_vectorchord} & Combina la ricerca per parole chiave (BM25) e la ricerca semantica (embedding vettoriali). & Bilancia precisione (ingredienti esatti) e recall (concetti culinari ampi). \cite{hybrid_search_vectorchord} & Maggiore complessità di implementazione e gestione. \cite{hybrid_search_vectorchord} \\
\addlinespace
Reranking \cite{mastering_rag_reranking} & Riordina i documenti recuperati inizialmente da un modello più preciso. & Riduce le allucinazioni e migliora la pertinenza dei risultati finali. \cite{mastering_rag_reranking} & Aumenta la latenza, costi computazionali aggiuntivi. \cite{reranking_mechanisms_medium} \\
\addlinespace
Recupero contestuale \cite{contextual_retrieval_pluralsight} & Arricchisce i chunk con metadati o riassunti del contesto più ampio del documento. & Rende i chunk più semanticamente ricchi e meno ambigui, anche con vocabolario ripetitivo. \cite{contextual_retrieval_mlexpert} & Aumenta la dimensione degli embedding, potenziale aumento dei costi di elaborazione. \cite{contextual_retrieval_somawansa} \\
\end{longtable}

\section{Fase 5: orchestrazione agentica - progettazione del sistema RAG intelligente}
Il requisito di un "sistema agentico" (query dell'utente) implica la necessità di un ragionamento dinamico e multi-step che vada oltre la semplice relazione query-risposta. Gli agenti possono decidere in modo intelligente come elaborare una query di ricetta (ad esempio, prima estrarre gli ingredienti, poi verificare le sostituzioni, quindi generare i passaggi di cottura), sfruttando diversi strumenti (NER, KG, RAG) secondo necessità. Questo rappresenta un significativo passo avanti rispetto al RAG tradizionale.

\subsection{Architettura del sistema agentico}
I sistemi RAG agentici introducono agenti di intelligenza artificiale nella pipeline per migliorare l'adattabilità e la precisione. \cite{what_is_agentic_rag_ibm} Questi agenti sono in grado di condurre il recupero di informazioni da più fonti, gestire workflow complessi e prendere decisioni autonome. Un sistema agentico per le ricette potrebbe, ad esempio, ricevere una query come "Come posso preparare una lasagna vegana usando gli ingredienti che ho?" L'agente utilizzerebbe prima il NER per identificare gli ingredienti disponibili, quindi interrogherebbe il KG per le sostituzioni vegane, recupererebbe i chunk di ricette pertinenti e infine sintetizzerebbe una risposta, adattando dinamicamente i suoi passaggi. Questo è un livello di intelligenza superiore rispetto a una pipeline RAG statica.
\begin{itemize}
    \item \textbf{Capacità degli agenti:}
    \begin{itemize}
        \item \textbf{Memoria:} gli agenti possiedono memoria a breve e lungo termine, che consente loro di pianificare ed eseguire compiti complessi, riferendosi a compiti precedenti per informare i workflow futuri. \cite{what_is_agentic_rag_ibm}
        \item \textbf{Pianificazione e decisione:} sono capaci di routing delle query, pianificazione passo-passo e processo decisionale. \cite{what_is_agentic_rag_ibm} Possono ragionare, scomporre compiti complicati in parti più piccole e sviluppare piani specifici per ciascuna parte. \cite{llm_agents_guide}
        \item \textbf{Utilizzo degli strumenti:} gli agenti possono effettuare chiamate a strumenti esterni tramite API, come interpreti di codice, vector store, o strumenti di ricerca per recuperare informazioni dalle knowledge base. \cite{what_is_agentic_rag_ibm}
        \item \textbf{Orchestrazione del workflow:} l'agente analizza la richiesta dell'utente, decide quali strumenti utilizzare, effettua le chiamate agli strumenti necessarie, sintetizza le informazioni da varie fonti e genera una risposta coerente. \cite{agentic_rag_workflow}
    \end{itemize}
\end{itemize}

\subsection{Integrazione di framework di ragionamento (ReAct, CoT)}
Per query di ricette complesse (ad esempio, "Suggerisci un dessert per una persona diabetica e intollerante al glutine usando le mele, e indicami l'impatto nutrizionale"), un semplice RAG potrebbe fallire. L'integrazione di framework di ragionamento consente all'agente di scomporre la query in sotto-problemi e di agire richiamando strumenti specifici in ogni fase, rendendo il processo di ragionamento trasparente e robusto. Un agente deve ragionare. \cite{reasoning_rag_survey}
\begin{itemize}
    \item \textbf{Chain-of-thought (CoT):} questa tecnica guida l'LLM attraverso un problema scomponendolo in più passaggi. \cite{prompt_engineering_explained} Migliora il ragionamento consentendo all'LLM di elaborare il problema in modo sequenziale, come farebbe un essere umano. È essenziale per compiti complessi di ricette (ad esempio, "Quali sono i passaggi per fare un lievito madre e cosa può andare storto?").
    \item \textbf{ReAct:} questo framework combina il ragionamento (simile a CoT) con la capacità di intraprendere azioni accedendo a risorse esterne (strumenti). \cite{prompt_engineering_explained} L'LLM decide quando recuperare più dati e genera passaggi di "pensiero-azione-osservazione" (thought-action-observation). Ad esempio, un "Pensiero" potrebbe essere "Devo trovare dolcificanti alternativi per una ricetta diabetica". L'"Azione" sarebbe "Chiamare lo strumento KG per trovare sostituti dello zucchero". L'"Osservazione" sarebbero i sostituti recuperati, che poi informano il successivo "Pensiero". Questo processo dinamico e iterativo è ciò che rende l'agente veramente intelligente e capace di gestire query di ricette complesse e sfaccettate. La combinazione di CoT e ReAct è spesso considerata ottimale. \cite{prompt_engineering_explained}
\end{itemize}

\subsection{Gestione delle informazioni conflittuali e mitigazione delle allucinazioni}
In un dominio come le ricette, possono sorgere informazioni contrastanti (ad esempio, diverse versioni di una ricetta, consigli dietetici contrastanti). Il sistema agentico deve essere progettato per rilevare e gestire questi conflitti \cite{dragged_into_conflicts}, piuttosto che limitarsi a presentarli, mantenendo così la coerenza fattuale e l'affidabilità. Ciò è cruciale per la sicurezza dell'utente (ad esempio, informazioni sugli allergeni). Le allucinazioni sono un rischio. \cite{mastering_rag_reranking}
\begin{itemize}
    \item \textbf{Rilevamento e gestione dei conflitti:} quando una strategia di recupero restituisce informazioni contraddittorie, l'LLM deve prima riconoscere il conflitto ed evitare di presentare affermazioni contrastanti come ugualmente valide senza contesto. \cite{milvus_contradictory_info} Il modello dovrebbe dare priorità all'identificazione delle discrepanze, alla valutazione dell'affidabilità della fonte e alla fornitura di una spiegazione equilibrata che evidenzi il disaccordo. \cite{milvus_contradictory_info}
    \item \textbf{Tassonomia dei conflitti:} una tassonomia dei tipi di conflitto può guidare il comportamento atteso del modello: nessun conflitto, informazioni complementari, opinioni o risultati di ricerca contrastanti, conflitto dovuto a informazioni obsolete, conflitto dovuto a disinformazione. \cite{dragged_into_conflicts}
    \item \textbf{Miglioramento del RAG:} il RAG aiuta a mitigare le allucinazioni basando le risposte su conoscenze esterne. \cite{beyond_traditional_finetuning} Tecniche come l'auto-affinamento tramite feedback e ragionamento possono migliorare iterativamente gli output degli LLM, portando a una migliore fattualità, coerenza e pertinenza. \cite{beyond_traditional_finetuning}
\end{itemize}

\begin{longtable}{>{\raggedright\arraybackslash}p{4cm} >{\raggedright\arraybackslash}p{6cm} >{\raggedright\arraybackslash}p{6cm}}
\caption{Componenti chiave e funzioni di un sistema RAG agentico}\\
\toprule
\textbf{Componente} & \textbf{Funzione principale} & \textbf{Ruolo nel contesto delle ricette} \\
\midrule
\endfirsthead
\multicolumn{3}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\toprule
\textbf{Componente} & \textbf{Funzione principale} & \textbf{Ruolo nel contesto delle ricette} \\
\midrule
\endhead
\bottomrule
\endfoot
Agenti AI \cite{what_is_agentic_rag_ibm} & Orchestrano il workflow, prendono decisioni autonome, gestiscono compiti complessi. & Analizzano query complesse su ricette, pianificano passaggi di ricerca e generazione. \\
\addlinespace
Memoria (breve/lungo termine) \cite{what_is_agentic_rag_ibm} & Conserva query passate, contesti, risultati e insight appresi. & Ricorda preferenze dietetiche dell'utente, ricette precedentemente cercate, workflow di risoluzione problemi. \\
\addlinespace
Pianificazione e ragionamento \cite{what_is_agentic_rag_ibm} & Scompone compiti complessi in sotto-compiti, sviluppa ed adatta piani (CoT, ReAct). & Scompone una richiesta di ricetta in fasi (es. identificare ingredienti, trovare sostituzioni, generare istruzioni). \\
\addlinespace
Utilizzo degli strumenti (tool calling) \cite{what_is_agentic_rag_ibm} & Interagisce con risorse esterne (NER, KG, Vector DB, API). & Chiama il NER per estrarre ingredienti, il KG per la disambiguazione/sostituzioni, il RAG per le ricette. \\
\addlinespace
Gestione conflitti \cite{dragged_into_conflicts} & Rileva e gestisce informazioni contraddittorie dalle fonti recuperate. & Identifica versioni contrastanti di ricette o consigli dietetici, fornisce risposte equilibrate. \\
\end{longtable}

\section{Scalabilità e considerazioni sull'implementazione}
L'implementazione di un sistema RAG agentico per documenti di ricette eterogenei richiede una solida infrastruttura sottostante, capace di gestire grandi volumi di dati e di evolvere con le esigenze del dominio.

\subsection{Selezione del vector database e strategie di indicizzazione}
Per un sistema RAG scalabile, la selezione di un vector database e una strategia di indicizzazione sono fondamentali. Dato il potenziale di milioni di ricette, tecniche come lo sharding e l'indicizzazione cluster-first sono vitali per mantenere bassa la latenza e alta la precisione del recupero. \cite{scaling_rag_millions} Ciò garantisce che, anche con una vasta collezione di ricette, il componente di recupero rimanga veloce e reattivo, essenziale per un sistema agentico in tempo reale.
\begin{itemize}
    \item \textbf{Gestione di dati ad alta dimensionalità:} i vector database sono progettati per gestire in modo efficiente dati ad alta dimensionalità sotto forma di vettori, cruciali per i sistemi RAG su larga scala. \cite{vector_databases_tutorial}
    \item \textbf{Scalabilità:} per dataset di milioni di documenti o più, è importante selezionare un vector database che supporti l'indicizzazione e le query distribuite, con soluzioni come Weaviate, Pinecone e PGVector che offrono scalabilità orizzontale tramite sharding e replicazione. \cite{scaling_rag_millions}
    \item \textbf{Tecniche di indicizzazione:}
    \begin{itemize}
        \item \textbf{HNSW (Hierarchical Navigable Small World):} frequentemente utilizzato per la ricerca di vicini più prossimi approssimati (ANN), ma può diventare meno efficiente con l'aumento del volume dei dati. \cite{scaling_rag_millions}
        \item \textbf{Metodi di indicizzazione cluster-first:} come IVF-PQ (Inverted File and Product Quantization), restringono lo spazio di ricerca indirizzando le query a cluster pertinenti prima di una traversata completa del grafo. \cite{scaling_rag_millions}
    \end{itemize}
\end{itemize}

\subsection{Flessibilità dello schema per dati di ricette in evoluzione}
I dati delle ricette sono intrinsecamente variabili (diversi formati, campi opzionali, nuove tendenze dietetiche). Un database con schema flessibile è altamente vantaggioso. Consente al sistema di acquisire diversi formati di ricette senza una rigida imposizione dello schema a priori, e di adattarsi man mano che emergono nuovi tipi di dati (ad esempio, nuove metriche nutrizionali, metodi di cottura), supportando il vincolo dei "documenti molto diversi".
\begin{itemize}
    \item \textbf{Natura dei dati non strutturati:} i dati non strutturati, come i PDF di ricette, mancano di un formato o uno schema rigido, rendendoli difficili da gestire per i database convenzionali. \cite{qdrant_vector_db} I vector database gestiscono questi dati rappresentandoli come vettori. \cite{qdrant_vector_db}
    \item \textbf{Modellazione dei dati grafici senza schema (schema-less graph data modeling):} questo approccio non richiede uno schema predefinito per archiviare o organizzare i dati. La struttura emerge dinamicamente man mano che vengono aggiunti nodi (entità), relazioni e le loro proprietà. \cite{schemaless_graph_modeling} Questo offre flessibilità per tipi di dati che evolvono o variano significativamente.
    \item \textbf{Flessibilità dello schema dei database:} database come MongoDB offrono flessibilità dello schema, non la sua assenza, consentendo di iniziare con un modello dati flessibile e di introdurre la convalida dello schema man mano che l'applicazione lo richiede. \cite{mongodb_flexible_schema} Questo approccio adattivo è ideale per la variabilità intrinseca dei dati delle ricette.
\end{itemize}

\subsection{Framework RAG eterogenei}
Per documenti altamente diversi, un framework RAG eterogeneo è un'ottimizzazione sofisticata. Permette al sistema di utilizzare "viste" diverse dei dati per le diverse fasi della pipeline RAG (ad esempio, una vista riassunta per il recupero iniziale, una vista dettagliata per la generazione), il che può migliorare significativamente le prestazioni e l'efficienza, specialmente quando si tratta di granularità di contenuto variabile all'interno delle ricette. I documenti dell'utente sono "molto diversi". Ciò significa che ciò che è ottimale per il recupero (ad esempio, un chunk conciso e semanticamente ricco) potrebbe non essere ottimale per la generazione (che potrebbe richiedere un testo più dettagliato e grezzo). HeteRAG \cite{heterag} affronta direttamente questo problema disaccoppiando le rappresentazioni. Per le ricette, questo potrebbe significare che per il recupero, i chunk sono arricchiti con metadati di ricette di alto livello, ma per la generazione, all'LLM viene fornito il testo completo e non riassunto della ricetta, consentendo sia una ricerca efficiente che una generazione di risposte dettagliate.
\begin{itemize}
    \item \textbf{Disaccoppiamento delle rappresentazioni:} i framework RAG eterogenei (HeteRAG) disaccoppiano le rappresentazioni dei chunk di conoscenza per le fasi di recupero e generazione, ottimizzando sia l'efficacia che l'efficienza. \cite{heterag}
    \item \textbf{Requisiti distinti:} le fasi di recupero e generazione hanno requisiti distinti per la granularità dei chunk di conoscenza. Il recupero richiede chunk che corrispondano accuratamente alle query dell'utente, mentre la generazione può beneficiare di chunk più contestualmente ricchi o completi. \cite{heterag}
    \item \textbf{Miglioramento delle prestazioni:} HeteRAG facilita la specializzazione dei modelli di embedding off-the-shelf, consentendo loro di gestire efficacemente corpus di conoscenza diversi e strutturalmente complessi del mondo reale. \cite{heterag}
\end{itemize}

\subsection{Metriche di valutazione e miglioramento continuo}
Per un sistema RAG di produzione, specialmente uno che gestisce informazioni sensibili come le restrizioni dietetiche, la valutazione continua è fondamentale. Le sfide dei "documenti molto diversi" e delle "parole che si ripetono frequentemente" implicano che la precisione del recupero e i tassi di allucinazione \cite{avoiding_hallucinations} potrebbero essere problemi significativi. Stabilire gold standard, test automatizzati e monitorare il drift \cite{rag_evaluation_metrics} sono fondamentali per garantire che il sistema rimanga affidabile e accurato nel tempo, adattandosi a nuovi formati di ricette o variazioni di ingredienti.
\begin{itemize}
    \item \textbf{Metriche di valutazione RAG:} le cinque metriche chiave per valutare le prestazioni del RAG includono la pertinenza del contesto, la sufficienza del contesto, la pertinenza della risposta, la correttezza della risposta e le allucinazioni della risposta. \cite{rag_evaluation_metrics}
    \item \textbf{Migliori pratiche:}
    \begin{itemize}
        \item \textbf{Stabilire un gold standard:} creare dataset di gold standard specifici per il caso d'uso all'inizio del ciclo di vita del progetto, con verifica manuale da parte di esperti di dominio. \cite{rag_evaluation_metrics}
        \item \textbf{Test automatizzati:} implementare pipeline di test automatizzate per gestire i cambiamenti continui nelle implementazioni RAG. \cite{rag_evaluation_metrics}
        \item \textbf{Evoluzione continua dei riferimenti:} i gold set devono essere continuamente migliorati e versionati man mano che vengono aggiunte nuove funzionalità. \cite{rag_evaluation_metrics}
        \item \textbf{Monitoraggio del drift:} stabilire soglie per il rilevamento del drift nelle prestazioni, attivando avvisi se vengono superate. \cite{rag_evaluation_metrics}
    \end{itemize}
\end{itemize}

\section{Conclusioni e raccomandazioni}
L'implementazione di un sistema RAG agentico per documenti di ricette eterogenei, senza dipendenza dal layout e con vocabolario ripetitivo, è un'impresa complessa ma realizzabile attraverso un approccio sistematico e multifase. La strategia proposta affronta le sfide intrinseche del dominio culinario, trasformando dati non strutturati e potenzialmente ambigui in una conoscenza strutturata e azionabile.
Il successo di un tale sistema si basa sulla sinergia tra i suoi componenti. Un'estrazione del testo robusta e indipendente dal layout, supportata da un preprocessing OCR avanzato e da LMM multimodali, costituisce la base affidabile. Il chunking intelligente, in particolare il chunking semantico e consapevole dei metadati, è fondamentale per creare unità di informazione coerenti e significative, superando le sfide del vocabolario ripetitivo. Il Riconoscimento di Entità Nominate (NER) specifico del dominio è il ponte essenziale che trasforma il testo in entità strutturate, alimentando la costruzione di un knowledge graph.
Il knowledge graph è un componente indispensabile per la disambiguazione delle entità, la normalizzazione dei sinonimi e la modellazione di relazioni complesse (ad esempio, sostituzioni, allergeni). La sua integrazione con il RAG (GraphRAG) eleva la capacità del sistema di eseguire ragionamenti complessi e di fornire risposte accurate e spiegate. Il recupero è ulteriormente potenziato dalla ricerca ibrida, che combina la precisione di BM25 con la comprensione contestuale della ricerca vettoriale, e dal reranking, che affina i risultati per massimizzare la pertinenza.
Infine, il livello di orchestrazione agentica, che incorpora framework di ragionamento come CoT e ReAct, consente al sistema di agire in modo autonomo, pianificare workflow complessi e utilizzare dinamicamente gli strumenti disponibili. Questa capacità di ragionamento e azione è cruciale per gestire query culinarie sfumate e per affrontare situazioni di informazione conflittuale, garantendo l'affidabilità e la sicurezza delle risposte.

\subsection*{Raccomandazioni:}
Le principali raccomandazioni per l'implementazione di un sistema RAG agentico per documenti di ricette eterogenei sono:
\begin{enumerate}[label=\arabic*.]
    \item \textbf{Dare priorità all'ingestione dei dati:} è cruciale investire nella fase di estrazione del testo e nel preprocessing OCR, poiché la qualità dell'input iniziale influisce sull'accuratezza dell'intero sistema. È consigliabile valutare l'uso di LMM multimodali, che possono comprendere documenti ricchi di elementi visivi senza dipendere da un layout specifico.
    \item \textbf{Sviluppare un NER e un KG specifici per il dominio:} è importante creare un modello NER accurato e un knowledge graph culinario. Sono strumenti essenziali per risolvere l'ambiguità del vocabolario e permettere un'analisi dettagliata di ingredienti, ricette e valori nutrizionali.
    \item \textbf{Implementare strategie di chunking avanzate:} si dovrebbero adottare tecniche di chunking semantico e basato sui metadati. Questo assicura che i chunk di testo siano coerenti e contestualizzati, anche quando contengono termini comuni.
    \item \textbf{Adottare un approccio di recupero ibrido con reranking:} combinare la ricerca BM25 e quella vettoriale, seguite da un reranker, migliora sia la precisione che la copertura nel recupero delle informazioni.
    \item \textbf{Progettare l'agente in modo iterativo:} il livello agentico dovrebbe essere sviluppato in modo incrementale, partendo dall'integrazione di CoT e ReAct per abilitare il ragionamento multi-step e l'uso di strumenti.
    \item \textbf{Implementare una valutazione continua:} è fondamentale stabilire metriche chiare e test automatizzati per monitorare le prestazioni, individuare derive e ridurre le allucinazioni, garantendo l'affidabilità del sistema nel tempo.
    \item \textbf{Considerare scalabilità e flessibilità dello schema:} è necessario scegliere vector database scalabili e adottare uno schema flessibile per la gestione dei dati, per permettere al sistema di crescere e adattarsi nel tempo.
\end{enumerate}

\bibliographystyle{plain}
\bibliography{bibliography.bib}

\end{document}